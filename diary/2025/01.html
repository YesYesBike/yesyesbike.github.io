<!DOCTYPE html>
<html>
	<head>
		<meta charset="UTF-8">
		<title>C, Perl, Linux</title>
	</head>
	<body>
		<h1>"No code is faster than no code." -Merb</h1>
		<hr>
		<p><a href="../../index.html">홈으로</a></p>
		<p><a href="../index.html">일기 목록</a></p>
		<p><a href="index.html">일기/2025년</a></p>
		<p><a href="../2024/12.html">&lt;- 12월</a></p>
		<br>
		<h2>2025/01/01</h2>
		<p>
새해를 맞은 기념으로 일기장 페이지를 새로 옮겼다.
프로그래밍 언어라고 부르면 온갖 사람들에게 욕을 얻어먹는 HTML이지만 이것만으로도 꽤 좋은 웹사이트를 만들 수 있다.
모든 복잡한 프로그램은 작성할 때뿐 아니라 그 뒤에도 커다란 짐이 된다.
마찬가지로 웹사이트도 여러가지 기능을 추가하면 유지보수하기 점점 어려워진다.
		</p>

		<p>
올해의 격언으로 'Deleted Code is Debugged Code'를 골랐다.
이는 소프트웨어 개발에서 절대 변하지 않을 진리 중 하나일 것이다.
어떤 코드를 작성하든 간에 그 순간 복잡성이 생겨나 언젠가는 완전히 통제할 수 없는 영역으로 도달할 것이다.
이는 버그의 원인이 된다. 디버깅 시간이 코드 길이의 제곱으로 증가함을 상기하자.
모든 버그를 확실하게 해결할 수 있는 Silver Bullet이 있다. 바로 코드를 말끔히 지워버리는 것이다.
이로써 책임 소재를 보다 분명하게 할 수 있다. 만약 하드웨어에 문제가 없다면 문제는 사라질 것이다.
		</p>

		<p>
코딩과 글쓰기의 공통점에 대해 생각해보자.
코딩을 할 때 처음에는 별다른 제약 없이 자유롭게 코드를 입력하더라도 괜찮다.
하지만 별 생각 없이 규모를 늘리다 보면 언젠가 대가를 치르게 된다.
코드 전체의 간단함을 유지하려면 그 방법을 떠올릴 수 있을 만큼 운이 좋아야 한다.
만약 그 방법을 모르겠다면 가만히 있는 게 좋다.
		</p>

		<br>

		<h2>2025/01/04</h2>
		<p>
최근에 아주 큰 깨달음을 얻었다. 프로그램에 어떤 기능을 추가하든 간에 그 코드는 성능을 더 나쁘게 할 수밖에 없음을 알았다.
모든 프로그램은 특정한 임무를 가진다. 정확히 계산하기는 어렵지만 할 수 있는 일이 늘어날수록 프로그램의 크기 또한 증가한다.
디렉토리를 생성하는 mkdir, 파일을 삭제하는 rm 등은 보통 한 가지 일만 한다.
awk는 좀 더 많은 일을 할 수 있고 perl은 상상할 수 있는 모든 일을 할 수 있다 카더라.
하나에 특화된 프로그램은 범용성 있는 프로그램보다 더 가볍다
(gawk가 perl보다 파일 크기가 더 큰 걸로 확인되었는데 라이브러리 등의 다른 요인이 있을 테니 넘어가겠다).
		</p>

		<p>
유닉스는 한 가지 일만 잘하는 여러 프로그램을 조합해 수많은 일을 해낼 수 있음을 입증했다.
불행히도 오늘날 존재하는 수많은 프로그램은 이를 그대로 적용하기 어렵다.
특히 사용자와 상호작용하는 프로그램은 독립적인 여러 프로그램으로 분리하기 꽤 힘들다.
텍스트 편집기를 예로 들어보자. 텍스트 편집기의 임무는 텍스트를 편집하는 것이다.
먼저 파일을 열어야 한다. 그러고 나서 글자를 입력한다. 오타를 지운다. 마지막으로 파일을 저장한다.
이 넷을 여러 프로세스에서 나누어 처리할 수 있지만(사실 쉘 하나에서 전부 처리할 수도 있다) 상당히 비효율적이다.
ed조차 하나의 프로세스에서 이를 해결할 수밖에 없었다.
		</p>

		<p>
결국 하나의 프로그램 안에서 여러 서브루틴을 잘게 쪼개는 방식을 택할 수밖에 없다.
비록 이들 각각이 하나의 온전한 프로그램으로 있을 수는 없지만 잘 만들어진다면 다른 프로그램에서도 써먹을 수 있다.
여기서 질문이 있다. 과연 이렇게 프로그램 안에서 구현한 함수가 다른 프로그램에서도 똑같이 쓰일 수 있을까?
할 수만 있다면 그렇게 하는 게 좋다. 실제로 자주 쓰는 함수를 라이브러리에 편입할 수 있다. 그렇지만 이는 일부에 불과하다.
웬만한 함수는 특정한 종류의 데이터를 특정한 방식으로 처리하기 때문에 다른 프로그램에서도 똑같은 형식의 데이터를 똑같이 처리할 필요가 생길 때에야 비로소 이를 재사용할 수 있다.
		</p>

		<p>
Kernighan의 법칙이 있다. 디버깅은 특정 코드를 작성하는 하는 것보다 두 배 더 어렵다는 법칙이다.
자신의 능력을 100% 발휘해서야 겨우 코드를 짠다면 그걸 디버깅하는 것은 법칙에 의해 불가능하다.
이 법칙이 주는 가르침은 여러가지가 있지만 이번에는 글쓰기에 초점을 맞춰보겠다.
자신이 아는 지식을 총동원해서 글을 작성한다면 거기에 있는 오류(자신이 오류임을 알 수 없는 것)가 뭔지 알 수 없다.
즉 외부 자료 없이 오로지 자신의 생각만을 바탕으로 글을 쓴다면 자신의 지식으로 오류를 수정할 수 없다.
글을 쓴 뒤 한참이 지나서야 비로소 자신의 실수나 무지나 오해를 깨닫게 된다.
약 3달 가량 일기를 되돌아보면서 꽤나 많은 곳에서 잘못된 점을 발견했다.
2024년 10월 12일(2일째) 일기에서부터 바로 오류를 발견하였다.
여기서는 EOF를 입력받으면 더 이상 입력을 받을 수 없다고 말했지만 clearerr()로 다시 입력을 받을 수 있게 할 수 있다.
이처럼 예전에 쓴 글에서 무지를 재발견하는 것은 불가피하다.
오류까지는 아니더라도 의견의 변화도 꽤 있었다.
하지만 여기에 일일이 적기에는 이미 시간이 너무 늦었다...
		</p>

		<br>

		<h2>2025/01/07</h2>
		<p>
임베디드 개발은 개발 환경을 갖추는 것부터 쉽지 않다.
순수 소프트웨어 개발에서는 버그가 생기면 소프트웨어 안에서 찾을 수 있지만(아닌 사례도 있을 것이다)
임베디드 개발에서는 원인을 찾기 더 힘들어진다. 하드웨어와 소프트웨어 두 군데 모두 신경써야 하기 때문이다.
하드웨어에서는 상상하기도 힘든 곳에서 온갖 버그가 생길 수 있다.
전선을 잘못 연결해서 생길 수 있고 전압을 너무 약하게 줘서 그럴 수 있고 이도 저도 아니면 부품 자체의 결함 때문일 수도 있다.
문제가 생기면 어느 부분이 문제인지 정확히 진단하는 게 소프트웨어보다 훨씬 어렵다.
이를 증명하려면 하드웨어에 대한 배경 지식과 경험을 갖추고 있어야 하기 때문이다.
실제로 무슨 일이 벌어지고 있는지 파악하는 것도 더 어렵다. 하드웨어에도 디버거가 있으나 쓰는 법을 알아야 한다.
그리고 나는 완전한 초짜라서 있어 봤자 조명 달린 장식 그 이상의 효용이 없다.
		</p>

		<p>
며칠 전 AVR 마이크로프로세서를 공부하려고 avr-gcc나 avrdude를 깔았다. 이런 소프트웨어적인 준비는 꽤나 쉬웠다.
atmega328p 칩을 빵판에 욱여넣고 LED를 켜기 위한 간단한 회로를 이었다. 여기까지는 순조로웠다.
문제는 그 뒤부터 시작되었다. 컴퓨터에서 MCU까지 프로그램을 전달하려면 ISP가 필요한데 이 과정에서 문제가 생겼다.
아두이노는 USB만 잘 연결하고 IDE에서 업로드 버튼만 누르면 별 탈 없이 프로그램이 전송된다.
그게 아니라 아예 칩만 달랑 있다면 얘기는 달라진다. MCU와 ISP 각각 대응하는 핀을 연결해야 한다.
그리고 알맞은 ISP의 옵션을 설정해줘야 한다. 여기서부터 소프트웨어 개발에서는 잘 없는 불확정성이 생겨난다.
		</p>

		<p>
소프트웨어 자체의 문제는 웹 검색으로 해결하기 쉽다. 왜냐하면 문제가 생긴 환경을 쉽게 재구성할 수 있기 때문이다.
포럼에 올라온 글을 살펴보면 질문 글에는 자신이 처한 상황이나 코드를 볼 수 있다.
만약 질문하는 사람이 잘 설명했다면 당사자가 아닌 사람도 해당 문제를 재현할 수 있다.
이를 통해 문제를 진단할 수 있는 사람이 답변할 수 있다.
하지만 하드웨어의 영역에 들어서면(달리 말해 매트릭스에서 벗어나면) 재현 가능성이 현저히 떨어진다.
질문하는 쪽에서 아무리 자세히 설명하고 여러 자료를 첨부한다 해도 글을 읽는 쪽에서 똑같이 재구성하지 못할 수 있다.
질문자가 실수로 중요한 정보를 빠뜨릴 수도 있는 노릇이라 글 자체만으로 모든 걸 알 수 없다.
의사도 진찰하기 전까지는 병의 원인을 잘 알 수 없다. 물론 나는 의사가 아니라서 이게 맞는지는 모른다.
		</p>

		<p>
이런 탓에 며칠째 같은 문제에서 벗어나지 못하고 있다.
게다가 이 작업은 다른 추후의 모든 일의 초석이 되는 준비 과정이라서 여기서 못 벗어나면 말 그대로 아무것도 못하게 된다.
지금 이 순간에도 어느 부분이 잘못되었는지 생각하고 있다.
먼저 현재 갖고 있는 유일한 ISP가 원하는 대로 작동을 안 한다.
이걸 사려고 피 같은 돈 x만원을 썼으나 아직 5볼트짜리 파워 서플라이 이상의 기능을 수행하지 못했다.
아두이노에 시험 삼아 프로그램을 올려봤는데 기기를 인식하는 것까진 됐으나 업로드 과정에서 문제가 생겼는지 업로드하기 전이랑 똑같이 작동했다.
대신 아두이노를 ISP로 써보려고 했으나 동영상 그대로 따라해도 오류를 내뱉었다.
아두이노를 ISP로 쓰려면 먼저 ISP 프로그램을 아두이노에 업로드한 뒤에 그걸 ISP 삼아 업로드하면 되는데 ISP를 인식하지 못한다.
과연 이 일기를 올리고 나서 고칠 수 있을지 모르겠다...
		</p>

		<br>

		<h2>2025/01/08</h2>
		<p>
프로그래머가 가장 자주 하는 말로 '왜 안 되지?'와 '왜 되지?' 둘이 있다는 유머를 들어봤을 것이다.
안 되다가 갑자기 되는데 그 이유를 전혀 모른다면 그건 문제를 해결한 게 아니라 덮어버린 것에 불과하다.
이러다가 나중에 똑같은 버그가 생길 수 있기 때문이다.
내 경험상 전자는 입에 달고 살 만큼 자주 있지만 후자의 경우는 매우 적다.
웬만한 버그는 확실한 원인이 있고 그걸 발견해야 비로소 고쳐지기 때문이다.
우연히 이러쿵저러쿵하다가 원인도 모른 채 고쳐진 경험은 지금 당장 떠오르지 않을 만큼 적다.
하지만 단 하나 오늘 후자의 상황이 펼져졌다.
		</p>

		<p>
먼저 어제의 문제가 해결되었다는 말을 하고 싶다.
하마터면 찬밥 신세가 될 뻔한 ISP가 제 몫을 해내서 매우 기쁘다.
어제 말했듯이 ISP 장비는 기기를 인식하는 것까지는 잘 해냈으나 업로드가 제대로 되지 않았다.
아두이노로 온갖 삽질을 해도 통하지 않자 자포자기의 심정으로 ISP로 마지막 한 번만 시도해보기로 했다.
그랬더니 업로드도 잘 되고 원하는 대로 잘 작동했다. 원인을 알아내고자 이것저것 뒤져봤으나 소용이 없었다.
나중에 밝혀진 바로는 avrdude의 여러 옵션들의 복합적인 작용이 원인인 것으로 밝혀졌다.
그런데 그 내막은 알 수 없어서 그대로 기권해버렸다.
-D 옵션 쪽이 원인인 듯하나 이 옵션을 달고도 잘 작동할 때가 있어서 이게 유일한 원인인지는 알 수 없다.
		</p>

		<p>
오늘 하루 동안 나를 괴롭혔던 또 다른 문제가 있다.
LED를 깜빡이는 것은 잘 됐으니 이제는 핀 여러 개로 LED를 껐다 켤 차례였다.
문제는 LED가 어느 쪽은 켜지는데 어느 쪽은 안 켜지는 것이었다.
MCU에서 전선으로 전류가 흐르지 않았는데 이게 MCU 자체의 문제인가 싶어 예비용 칩으로 교체해봤으나 결과는 똑같았다.
바꾸기 전과 후 모두 특정한 전선에서 전류가 흐르지 않았다.
atmega328p의 설계 상 특정 핀을 출력하지 않게끔 기본으로 설정되어있나 싶어서 이것저것 뒤져보고 싶었으나 키워드를 뭐로 해야 할지 알 수 없었다.
여러 삽질을 하며 끙끙거리다 이내 해답을 찾았다.
브레드보드에 칩이 완전히 꽃히지 않았던 것이다. 그것도 모르고 여러 헛짓거리를 했다.
		</p>

		<p>
아직 해결하지 못한 문제가 남아있다. 클록 설정이 제대로 안 되었는지 프로그램 상의 대기 시간과 실제 시간에 차이가 있다.
아두이노에 기본으로 장착된 크리스탈이 없어 그냥 칩만 장착해서 그런 것 같다.
칩 자체의 타이머로 클록을 설정하는 방법이 있는 듯하지만 뭘 해야할지 모르겠다.
		</p>

		<br>

		<h2>2025/01/14</h2>
		<p>
개발할 프로그램의 명령어 인터프리터로 내장할 언어를 찾아볼 요량으로 Lua를 공부했다.
마침 Neovim에서 스크립트용으로 사용하고 있었고 간단함을 지향하길래 괜찮다고 생각했다. 이는 오판이었다.
Lua는 C와 밀접하게 연관되어 있다. 일단 인터프리터 자체가 C언어로 쓰였다.
스크립트를 실행할 때 C 표준 라이브러리 함수를 호출하고 두 언어 사이의 API 지원도 상당히 잘 되어있다.
하지만 내게 Lua를 배우는 과정은 그다지 유쾌하지 않았다.
C언어 문법에 익숙한 내게 Lua는 상당한 혼란을 일으켰다.
		</p>

		<p>
이 둘의 결정적인 차이점은 다음과 같다.
<ol>
	<li>Lua의 배열(정확히 말하자면 테이블)은 첫 번째 원소의 인덱스가 1이다.</li>
	<li>Lua는 같지 않음을 나타내는 연산자로 ~=를 사용한다.</li>
	<li>(2와 연관됨)C에서 있는 복합 대입 연산자(+=, -= 등)가 Lua에는 없다.</li>
	<li>Lua는 논리 연산자(&amp;&amp;, ||)가 없고 대신 and, or 키워드가 있다.</li>
	<li>Lua는 삼항 연산자(?:)가 없다! a and b or c를 써야 한다.</li>
	<li>Lua는 정수 나눗셈 연산자로 //를 사용한다.</li>
	<li>주석도 상당한 차이가 있다. --[[를 쓰는 언어는 내가 아는 한에서 Lua 하나뿐이다.</li>
	<li>Lua는 C언어의 ++, -- 연산자가 없어서 똑같은 일을 하려면 var = var + 1를 쓰는 수밖에 없다.</li>
</ol>
그 외에도 중괄호로 묶는 대신 then/do와 end를 쓰는 알골식 문법 등이 있다.
		</p>

		<p>
내가 C언어에 지나치게 매몰되어 새로운 걸 받아들이지 못하게 된 걸지도 모른다.
하지만 최소 놀람의 법칙을 되새겨보자. Lua는 이를 정면으로 위반했다고 볼 수 있다.
별다른 이유 없이 인터페이스, 기능 등을 뜯어 고친다면 사용자는 새로운 사용법을 또 익혀야 하고 기존 지식과 상충하는 사항 때문에 고생을 겪는다.
분명 Lua에게도 이런 변화를 준 데에 합당한 이유가 있을 것이다.
중괄호를 쓰는 대신에 알골식 문법을 차용한 것은 테이블이 중괄호를 써야하기 때문인 것처럼 말이다.
8번 항목에 해당하는 단항 증감연산자도 버그를 유발할 수 있기 때문에 삭제한 것으로 보인다.
하지만 여전히 왜 첫 번째 원소의 인덱스를 1로 지정했지는 모르겠다. <strong>나무삼!</strong>
		</p>

		<br>

		<h2>2025/01/15</h2>
		<p>
작성되지 않은 코드에는 억만금의 가치가 있다. 거기에는 무한한 가능성이 있다.
어리석은 프로그래머는 1만 줄의 코드로 문제를 해결하지만 현명한 프로그래머는 코드를 작성하지 않고 똑같은 일을 해낸다.
완벽은 더할 게 없을 때 이루어지는 게 아니라 더 이상 뺄 게 없을 때에 이루어진다.
		</p>
		
		<p>
어제에 이어서 다른 후보인 Scheme을 공부했다.
값을 최대한 늦게 계산해 데이터 손실을 막을 수 있다는 이점이 있다.
불행히도 아직 이걸로 제대로 된 프로그램을 짤 실력이 안 된다.
여러 입문 자료를 읽다보면 모두들 하나같이 리스프가 간단하고 금방 배울 수 있다고 말한다.
여기에는 함정이 숨어있다. 금방 배울 수 있다고 해서 하룻밤에 뚝딱 해치울 수 있는 건 아니다.
문법은 상당히 간단하다. 괄호에서 시작해서 괄호로 끝난다. 여기에 첫 번째 난관이 있다.
리스프를 사용한다면 전용 기능을 지원하는 편집기가 반드시 있어야 한다.
괄호가 짝이 맞는지 확인하는 기능과 자동으로 들여쓰기를 정리해주는 기능은 필수다.
하지만 이를 갖춰도 문법 오류를 찾아내기는 역부족이다.
똑같이 따라 쳤는데도 오류를 내뱉는 광경을 지켜보고 있자면 옛날에 자바로 코딩하던 시절의 안 좋은 기억이 떠오른다.
참다 못해 예제 코드를 복붙하면 오류가 말끔히 사라지는데 이때 수많은 생각이 머리를 스쳐 지나간다.
이런 종류의 오류는 보통 괄호 하나 때문에 생겨나는데 이런 괄호가 코드 전체에 산더미만큼 산재해 있다.
한눈에 오류를 파악해내기란 거의 불가능하다.
		</p>

		<p>
이를 감안하더라도 수많은 낯선 개념들이 발목을 잡는다.
아마 그 첫 관문이 람다일 것이다. 한때 이게 뭔지 이해하려고 한참을 고민했던 기억이 있다.
지금은 이게 이름 없이 프로시저 그 자체를 표기하는 방식임을 알지만 당시에는 완전한 넌센스였다.
그걸 이해하고 나서도 여전히 혼란스러운 개념들이 앞에 널려있다.
let과 letrec의 차이점을 몰라서 좌절에 빠졌던 적도 있다.
(cons 'a '(b))의 결과는 (a b)이고 (cons 'a 'b)의 결과는 (a . b)이다.
이 미묘한 차이를 알려면 먼저 cons 프로시저의 작동 원리를 알아야 한다.
C를 (cons 'A 'B)라고 한다면 (car C)는 A이고 (cdr C)는 B이다.
<a href="https://conservatory.scheme.org/schemers/Documents/Standards/R5RS/HTML/r5rs-Z-H-9.html#%_idx_390">
	이게 cons의 정의다.</a>
이걸 알더라도 여전히 의문은 사라지지 않는다. (a b)와 (a . b)는 뭐가 다른 건가?
결론만 말하자면 전자는 리스트이고 후자는 <a href="https://conservatory.scheme.org/schemers/Documents/Standards/R5RS/HTML/r5rs-Z-H-2.html#%_toc_%_sec_6.3.2">pair</a>다.
pair는 리스트와는 생긴 건 비슷하지만 다르다.
		</p>

		<p>
깜빡하고 얘기를 안 한 사실이 있다. Scheme을 공부한 게 이번이 처음이 아니다.
오늘 말고도 이렇게 Scheme에 도전한 게 열 번은 족히 넘을 것이다.
처음 Scheme을 접하게 된 계기는 너무나 잘 알려진 고전인 SICP였다.
본문 난이도도 상당하지만 연습 문제도 매우 어렵다. 아직까지도 1장을 넘어서지 못하고 있다.
MIT에서는 입문서겠지만 나는 그 정도로 유능하지는 않아서 SICP로 공부하는 건 그만두기로 했다.
이번에는 다른 전략을 취했다. 머나먼 꿈인 SICP는 내버려두고 대신 문법 자체를 공부하는 데에 초점을 두었다.
R5RS 공식 문서의 쪽수가 50쪽밖에 안 되지만 레퍼런스 매뉴얼답게 읽기 어려운 부분이 있다.
그래서 튜토리얼로 읽을 만한 자료를 찾았다. 괜찮은 게 꽤 많이 있었다.
<ul>
	<li><a href="https://files.spritely.institute/papers/scheme-primer.html">A Scheme Primer</a></li>
	<li><a href="https://scheme.com/tspl4/">The Scheme Programming Language</a></li>
	<li><a href="https://ds26gte.github.io/tyscheme/index-Z-H-1.html">Teach Yourself Scheme in Fixnum Days</a></li>
	<li><a href="https://docs.scheme.org/schintro/">An Introduction to Scheme and its Implementation</a></li>
	<li><a href="https://docs.scheme.org/guide/">Scheme.org Guide</a></li>
	<li><a href="https://en.wikibooks.org/wiki/Scheme_Programming">Wikibooks Scheme Programming</a></li>
	<li><a href="https://lips.js.org/docs/category/introduction-to-scheme">Introduction to Scheme</a></li>
	<li><a href="https://docs.scheme.org/">Scheme.org Docs</a></li>
</ul>
이 목록에 있는 튜토리얼을 끝낸 다음에 레퍼런스 매뉴얼을 읽으면 될 것 같다.
아니, 그 전에 <a href="https://htdp.org/2023-8-14/Book/index.html">How to Desing Programs</a>를 읽어야겠다.
		</p>
	</body>
</html>
